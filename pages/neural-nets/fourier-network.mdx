# Fourier Network

Neural networks sometimes have a preference for low-frequency solutions, an issue called "spectral bias."
This can negatively impact how well the model learns during training and the accuracy of the 
final model. To help with this problem, we can use a technique called **input encoding**. This means transforming the inputs 
into a higher dimensional feature space through high-frequency functions. Fourier networks are a great way to do this!

The input encoding layer in SIML.ai is a variation of the one proposed in <sup>[1](#ref-1)</sup>, but adds a twist with trainable encoding,
which makes it even more powerful!

For some more complex examples, we can also apply encoding to other parameters besides the inputs themselves. 
This can make the model even more accurate and help it learn faster. The Modulus module in SIML.ai takes care of 
applying input encoding to both the inputs and the other parameters in a fully decoupled setting and then concatenates 
the spatial/temporal and parametric Fourier features together.

So, in a nutshell, Fourier networks and input encoding can help neural networks overcome their preference for low-frequency solutions, 
leading to better learning and more accurate models.

---

References:

- <div id="ref-1">[1] Tancik, Matthew, et al. ["Fourier features let networks learn high frequency functions in low dimensional domains."](https://arxiv.org/abs/2006.10739) Advances in Neural Information Processing Systems 33 (2020): 7537-7547.</div>